# Copy to config/settings.yaml and customize for your environment

orchestrator:
  provider: "anthropic"
  model: "claude-3-5-sonnet"
  temperature: 0.2
  max_output_tokens: 1024
  fallback_model: "llama3-8b-instruct"
  memory_backend: "redis://localhost:6379/0"
  audit_log_path: "/var/lib/maxos/audit.log"

agents:
  filesystem:
    root_whitelist:
      - "/home"
      - "/srv"
    require_confirmation_over_mb: 50
    confirmation:
      enabled: true
      require_for_operations:
        - copy
        - move
        - delete
      auto_approve_under_mb: 10  # Auto-approve operations < 10MB
    rollback:
      enabled: true
      trash_retention_days: 30
      max_trash_size_gb: 50
    transactions:
      db_path: "~/.maxos/transactions.db"
      log_all_operations: true
  system:
    allowed_units:
      - "ssh.service"
      - "docker.service"
  developer:
    default_stack: "fastapi-react"
    git_provider: "github"
  network:
    allowed_interfaces:
      - "wlan0"
      - "eth0"

llm:
  anthropic_api_key: "set-me"
  openai_api_key: "optional"
  google_api_key: "optional"  # For multi-agent system with Gemini
  local_model_path: "/opt/models/llama3-8b.gguf"
  # LLM-powered intent classification settings (uses orchestrator.provider and orchestrator.model)
  fallback_to_rules: true         # Fall back to keyword matching if LLM fails
  max_tokens: 500                 # Max tokens for classification response
  temperature: 0.1                # Low temperature for consistent classification
  timeout_seconds: 10             # Request timeout

# Multi-agent orchestration system
multi_agent:
  enabled: false  # Enable to use multi-agent system
  google_api_key: "set-me"  # Or use GOOGLE_API_KEY env var
  max_debate_rounds: 3
  consensus_threshold: 0.8
  route_complex_queries: true  # Auto-route complex queries to multi-agent

# Google AI Stack - Voice, Vision, and Multimodal
voice:
  input:
    provider: google_cloud
    model: chirp-2  # Latest Google STT (2024)
    language: en-US
    streaming: true
    google_cloud_project: "${GOOGLE_CLOUD_PROJECT}"
    credentials: "${GOOGLE_APPLICATION_CREDENTIALS}"
  
  output:
    provider: google_cloud
    voice: en-US-Studio-O  # Ultra-realistic Studio voice
    speaking_rate: 1.0
    pitch: 0.0
    google_cloud_project: "${GOOGLE_CLOUD_PROJECT}"
    credentials: "${GOOGLE_APPLICATION_CREDENTIALS}"
  
  wake_word: "hey max"
  wake_word_sensitivity: 0.5

vision:
  provider: mediapipe  # Google's MediaPipe
  enable_hand_tracking: true
  enable_face_tracking: true
  enable_pose_tracking: false  # Optional
  enable_eye_gaze: true
  
  camera_index: 0
  resolution: [1280, 720]
  fps: 60
  
  gestures:
    enabled: true
    custom_gestures_path: "config/custom_gestures.yaml"
  
  cursor_control:
    mode: gaze  # or "hand" for hand-pointer
    smoothing: 0.7
    sensitivity: 1.0

multimodal:
  enabled: false  # Enable to use multimodal voice+vision control
  gemini_model: gemini-2.0-flash  # Latest multimodal model
  combine_voice_and_vision: true  # Send camera context with voice commands
  gesture_override_voice: false  # Gestures take priority
  
  no_keyboard_mode: false  # Disable keyboard/mouse entirely
  fallback_keyboard: true  # Emergency keyboard access

cloud:
  google_cloud_project: "${GOOGLE_CLOUD_PROJECT}"
  google_application_credentials: "${GOOGLE_APPLICATION_CREDENTIALS}"
  
  # Optional: Use Google Cloud Vision for advanced image analysis
  vision_api:
    enabled: false
    features:
      - text_detection  # OCR
      - object_localization
      - face_detection
      - landmark_detection

policy:
  require_mfa: true
  confirmation_thresholds:
    destructive: true
    filesystem: 100
    systemd: true

logging:
  level: "INFO"
  json: true
  file: "logs/maxos.log"

telemetry:
  enabled: false
  endpoint: "https://telemetry.tezzaworks.ai"
  # Google Analytics configuration (optional)
  google_analytics:
    measurement_id: "G-XXXXXXXXXX"  # Your GA4 Measurement ID
    api_secret: "your-api-secret"   # Your Measurement Protocol API Secret
